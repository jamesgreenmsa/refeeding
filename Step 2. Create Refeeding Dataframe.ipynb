{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOagNYJlhB3AFh8kc+khjXP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["##Program 2/2, Data Analysis\n","\n","Refeeding Data Analysis Script To Create Analytic File For\n","Doctoral Research Project\n","\n","Programmer: James Green,\n","Email: jg1984@shp.rutgers.edu,\n","Updated: 10/17/2024"],"metadata":{"id":"hPfY3NegUMGT"}},{"cell_type":"markdown","source":["Step 1) Load the Google Drive"],"metadata":{"id":"Rp7xSYp8Toy_"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IF4KDpZ8mxA1","executionInfo":{"status":"ok","timestamp":1730669869429,"user_tz":300,"elapsed":18644,"user":{"displayName":"James Green","userId":"17673549078097849510"}},"outputId":"760111f9-1192-44b2-d88c-aaa611d6af52"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["Step 2) New function to import and join files"],"metadata":{"id":"JsVhbQoKQPXc"}},{"cell_type":"code","source":["import os\n","import pandas as pd\n","\n","def join_csv(file_name, base_df=None, join_vars=None, join_type='inner', nrows=None):\n","    \"\"\"\n","    Joins a CSV file with an existing DataFrame, or returns the first table if no base_df is provided.\n","\n","    Parameters:\n","    - file_name (str): The path to the CSV file to join.\n","    - base_df (pd.DataFrame or None): The DataFrame to join to. If None, the function returns the CSV as the base DataFrame.\n","    - join_vars (list or str, optional): Columns to join on (must exist in both DataFrames). Default is None.\n","    - join_type (str, optional): Type of join - 'left', 'right', 'inner', or 'outer'. Default is 'inner'.\n","    - nrows (int, optional): Number of rows to load from the CSV. Default is None (loads full table).\n","\n","    Returns:\n","    - pd.DataFrame: The result of the join operation or the loaded CSV if no base DataFrame is given.\n","    \"\"\"\n","    try:\n","        # Load the CSV file with optional row limit\n","        new_df = pd.read_csv(file_name, nrows=nrows)\n","\n","        # If no base DataFrame is provided, return the new DataFrame as the starting point\n","        if base_df is None:\n","            print(f\"Loaded initial DataFrame from {file_name} with {nrows or 'all'} rows.\")\n","            return new_df\n","\n","        # Ensure join variables are provided before attempting the join\n","        if join_vars is None:\n","            raise ValueError(\"Join variables must be specified for joining.\")\n","\n","        # Perform the join operation\n","        result_df = pd.merge(base_df, new_df, on=join_vars, how=join_type)\n","\n","        print(f\"Joined {file_name} using {join_type} join on {join_vars} with {nrows or 'all'} rows.\")\n","        return result_df\n","\n","    except FileNotFoundError:\n","        print(f\"File {file_name} not found.\")\n","        return base_df if base_df is not None else pd.DataFrame()\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","        return base_df if base_df is not None else pd.DataFrame()\n"],"metadata":{"id":"PZnkP_RnQ4hU","executionInfo":{"status":"ok","timestamp":1730669873025,"user_tz":300,"elapsed":816,"user":{"displayName":"James Green","userId":"17673549078097849510"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["Step 3) Call the join_csv function to import and join each file to the larger analytic dataframe"],"metadata":{"id":"J9cpmRQyT9aN"}},{"cell_type":"code","source":["# Directory path containing the CSV files\n","path = '/content/drive/MyDrive/Research/DHI/Refeeding/icu/'\n","\n","# List of tables with join variables, types, and row limits (if needed)\n","join_instructions = [\n","    # (file_name, join_columns, join_type, nrows)\n","    ('icustays.csv', ['subject_id', 'hadm_id', 'stay_id'], None, None),  # Last parameter is row limitation, All rows selected with 'None'\n","    ('chartevents.csv', ['subject_id', 'hadm_id', 'stay_id'], 'left', None),\n","    ('inputevents.csv', ['subject_id', 'hadm_id', 'stay_id'], 'left', None)\n","]\n","\n","# Initialize base DataFrame as None\n","base_df = None\n","\n","# Loop through the join instructions and perform each join sequentially\n","for file_info in join_instructions:\n","    file_name, join_vars, join_type, nrows = file_info\n","\n","    # Construct full file path\n","    full_path = os.path.join(path, file_name)\n","\n","    # Call the join function, passing None as base_df for the first file\n","    base_df = join_csv(\n","        file_name=full_path,\n","        base_df=base_df,\n","        join_vars=join_vars,\n","        join_type=join_type if join_type else 'inner',\n","        nrows=nrows\n","    )\n","\n","# Save the final DataFrame to a CSV file\n","output_path = '/content/drive/MyDrive/Research/DHI/Refeeding/icu/final_joined_data.csv'\n","base_df.to_csv(output_path, index=False)\n","\n","print(f\"Final joined DataFrame saved to {output_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jjoZhiZXVMo-","outputId":"ef021a99-d26f-445d-d5cd-e0f3809ffc31"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded initial DataFrame from /content/drive/MyDrive/Research/DHI/Refeeding/icu/icustays.csv with all rows.\n"]}]},{"cell_type":"markdown","source":["Step 4) Limit the dataframe to only those variables needed for the study."],"metadata":{"id":"OhjGantdl-Mv"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# List of final columns that we want from the joined files\n","variable_list = ['subject_id', 'hadm_id', 'stay_id', 'itemid_x', 'itemid_y', 'first_careunit', 'intime' , 'outtime', 'los', 'value'\n",", 'valueuom',  'starttime', 'endtime' , 'amount', 'amountuom', 'rate', 'rateuom']\n","\n","# Create a new dataframe with only the specified columns and without duplicates\n","filtered_df = base_df[variable_list].drop_duplicates()\n","\n","# Display the resulting dataframe\n","filtered_df.head()\n","\n","# Save the final DataFrame to a CSV file\n","output_path = '/content/drive/MyDrive/Research/DHI/Refeeding/icu/final_filtered_joined_data.csv'\n","filtered_df.to_csv(output_path, index=False)\n","\n","print(f\"Final filtered and joined DataFrame saved to {output_path}\")\n","\n","# Optionally, print the first few rows to verify\n","print(filtered_df.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IeKzcjWamFG8","executionInfo":{"status":"ok","timestamp":1730599151579,"user_tz":240,"elapsed":190,"user":{"displayName":"James Green","userId":"17673549078097849510"}},"outputId":"e70c3ea0-4798-40e3-f6d2-5ceebf7afb9f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Final filtered and joined DataFrame saved to /content/drive/MyDrive/Research/DHI/Refeeding/icu/final_filtered_joined_data.csv\n","   subject_id   hadm_id   stay_id  itemid_x  itemid_y  \\\n","0    10000032  29079034  39553978  220179.0  226452.0   \n","1    10000032  29079034  39553978  220179.0  226452.0   \n","2    10000032  29079034  39553978  220179.0  220862.0   \n","3    10000032  29079034  39553978  220179.0  220862.0   \n","4    10000032  29079034  39553978  220179.0  226452.0   \n","\n","                       first_careunit               intime  \\\n","0  Medical Intensive Care Unit (MICU)  2180-07-23 14:00:00   \n","1  Medical Intensive Care Unit (MICU)  2180-07-23 14:00:00   \n","2  Medical Intensive Care Unit (MICU)  2180-07-23 14:00:00   \n","3  Medical Intensive Care Unit (MICU)  2180-07-23 14:00:00   \n","4  Medical Intensive Care Unit (MICU)  2180-07-23 14:00:00   \n","\n","               outtime       los value valueuom            starttime  \\\n","0  2180-07-23 23:50:47  0.410266    82     mmHg  2180-07-23 21:10:00   \n","1  2180-07-23 23:50:47  0.410266    82     mmHg  2180-07-23 17:00:00   \n","2  2180-07-23 23:50:47  0.410266    82     mmHg  2180-07-23 17:00:00   \n","3  2180-07-23 23:50:47  0.410266    82     mmHg  2180-07-23 17:33:00   \n","4  2180-07-23 23:50:47  0.410266    82     mmHg  2180-07-23 18:56:00   \n","\n","               endtime      amount amountuom   rate  rateuom  \n","0  2180-07-23 21:11:00  100.000000        ml    NaN      NaN  \n","1  2180-07-23 17:01:00  200.000000        ml    NaN      NaN  \n","2  2180-07-23 17:30:00   49.999999        ml  100.0  mL/hour  \n","3  2180-07-23 18:03:00   49.999999        ml  100.0  mL/hour  \n","4  2180-07-23 18:57:00  100.000000        ml    NaN      NaN  \n"]}]}]}